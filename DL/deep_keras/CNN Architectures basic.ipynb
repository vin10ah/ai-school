{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-9MRzNjm-NN"
   },
   "source": [
    "# CNN Architectures basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MVSOTfMw_Yv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wEyROccw462"
   },
   "source": [
    "## 목차\n",
    "#### 1. LeNet-5\n",
    "#### 2. AlexNet\n",
    "#### 3. VGGNet\n",
    "#### 4. ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-1fZ4qIxCVd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ilEigbynBPF"
   },
   "source": [
    "## 1. LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**논문**: [Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/document/726791)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAA0G5DUnhFL"
   },
   "source": [
    "처음 소개해드릴 모델은 딥러닝에서 이미지 분류에 가장 보편적으로 사용되는 Convolutional Neural Network(CNN)을 처음으로 제안한 얀 르쿤(Yann LeCun)의 **LeNet-5**입니다. 프랑스 출신의 컴퓨터 과학자 [얀 르쿤](https://en.wikipedia.org/wiki/Yann_LeCun)은 '인공지능 4대 천왕'([제프리 힌튼](https://en.wikipedia.org/wiki/Geoffrey_Hinton), 얀 르쿤, [요슈아 벤지오](https://en.wikipedia.org/wiki/Yoshua_Bengio), [앤드류 응](https://en.wikipedia.org/wiki/Andrew_Ng))이라고 불리는 석학 중 한 명입니다. 1989년, AT&T 벨 연구소에 있을 때 얀 르쿤은 동료들과 함께 오류 역전파 기법을 기반으로 하여 손으로 작성된 우편물의 우편번호(zip code)를 인식하여 자동으로 분류할 수 있는 소프트웨어를 개발하여 상용화하였습니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o1okMUH6fKC"
   },
   "source": [
    "<center><img src=\"https://rtn.one/wa-data/public/site/rtn/061/000/061000052.png\" alt=\"Example\" align=\"center\" width=\"500\" height=auto></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JKWTmWQ6Cwr"
   },
   "source": [
    "LeNet-5은 얀 르쿤 연구팀이 1998년에 개발한 CNN 알고리즘의 이름입니다. 1990년에 개발된 LeNet-1부터 시작하여 LeNet-4를 거쳐, 1998년 얀 르쿤 연구팀에 의해 LeNet-5 모델이 개발되었습니다. 'LeNet'이라는 이름은 'LeCun'과 'Network'의 결합으로 만들어졌습니다. (LeNet-2와 LeNet-3은 존재하지 않습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a30m43GnXsE"
   },
   "source": [
    "(참고) 1993년도에 촬영된 LeNet-1의 데모 영상을 다음의 링크에서 확인할 수 있습니다. 얀 르쿤의 젊은 시절 모습이 보이네요!\n",
    "https://youtu.be/FwFduRA_L6Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nn9Byj3-bOn"
   },
   "source": [
    "LeNet-5의 구조를 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1kqfJlInt4J"
   },
   "source": [
    "<center><img src=\"https://miro.medium.com/max/1400/1*FTqJDxQSvqRULVaNLwcfxw.png\" alt=\"LeNet5\" align=\"center\" border=\"0\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiinRAIm-oIs"
   },
   "source": [
    "LeNet-5는 위의 그림과 같이 input layer와, 3개의 Convolution layer(C1, C3, C5), 2개의 Subsampling layer(S2, S4), 1 개의 full-connected layer(F6), output layer로 구성되어 있습니다. C1부터 F6까지 활성화 함수(activation function)로 tanh(하이퍼볼릭 탄젠트) 함수를 사용합니다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfqI7k-N_AUc"
   },
   "source": [
    "Layer의 순서대로 구체적으로 정리해보면 다음과 같습니다.\n",
    "\n",
    "- **Input Layer:** 32×32 input image\n",
    "- **C1:** 입력 이미지($32 \\times 32$)에 6개의 $5 \\times 5$ 필터와 Conovolution 연산을 적용하여 6개의 $28 \\times 28$ feature map을 얻게 됩니다. \n",
    "- **S2:** C1 레이어에서 나온 6개의 feature map($28 \\times 28$) 에 Subsampling을 수행합니다. 이때 사용하는 Subsampling은 Average Pooling 방식이고 사이즈를 두배로 줄여서 각 feature map의 크기는 $14 \\times 14$가 됩니다.\n",
    "- **C3:** 6개의 $14 \\times 14$ feature map에 Convolution 연산을 수행하여 16개의 $10 \\times 10$ feature map을 얻습니다.\n",
    "- **S4:** C3의 feature map에 마찬가지로 사이즈를 두배로 줄이는 Subsampling(Average Pooling)을 적용하여 $5 \\times 5$로 줄입니다.\n",
    "- **C5:** 120개의 뉴런으로 구성된 Fully-connected layer입니다.\n",
    "- **F6:** 84개의 뉴런으로 구성된 Fully-connected layer입니다.\n",
    "- **Output Layer:** 10개의 뉴런으로 구성된 Fully-connected layer입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSCfNuj8_7Dc"
   },
   "source": [
    "잠깐 LeNet-1의 구조와 비교해볼까요? 크기만 작을 뿐, LeNet-5와 유사한 구조를 가지고 있음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyD_Cpi2_EUC"
   },
   "source": [
    "<center><img src=\"https://kjhov195.github.io/post_img/200210/image0.png\" alt=\"LeNet5\" align=\"center\" border=\"0\" width=\"500\" height=auto></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 지금까지 설명한 LeNet-5를 Tensorflow를 통해 구현한 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YhY1WKHqb7vC"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RkmoAfrs6JKY"
   },
   "outputs": [],
   "source": [
    "def LeNet(input_shape, nb_classes):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    model = Sequential(name='LeNet')\n",
    "    model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation='tanh'))\n",
    "    model.add(Dense(84, activation='tanh'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=categorical_crossentropy,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SzcHAJgD5f7"
   },
   "source": [
    "## 2. AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**논문**: [ImageNet Classification with Deep Convolutional Neural Networks (NIPS 2012)](http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 LeNet은 구조적 한계로 숫자 분류 이상의 작업을 해내는 데에는 어려움이 있었습니다. 그러면서 1992년 처음 등장하여 기계학습 학계와 업계를 휩쓸다시피 한 Support Vector Machine(SVM)의 등장으로 CNN을 비롯한 인공 신경망의 인기가 시들해졌습니다. 당시에는 컴퓨팅 파워에도 한계가 있었기 때문에 LeNet에서 사용한 Convolutional layer의 개수를 늘림으로써 모델 성능을 늘리는 것에도 한계가 있었습니다.\n",
    "\n",
    "하지만 **이미지 분류 문제**는 컴퓨터 비전을 연구하는 연구자들에게는 굉장히 중요한 문제 중 하나였고, 비록 인공 신경망의 인기가 식었을지언정 비전 연구자들은 분류 문제를 계속 풀고자 시도하였습니다. 그리고 어느 분야든 논문을 작성할 때는 공통된 벤치마크 데이터셋으로 성능을 이야기하는 것이 일반적입니다. 때문에 비전 분야에서도 2009년 **ImageNet**이라는 매우 유명한 벤치마크 데이터셋이 스탠포드 대학으로부터 공개되었습니다. 그리고 이를 이용한 경진대회인 **ILSVRC(ImageNet Large Scale Visual Recognition Challenge)** 또한 함께 열렸습니다.\n",
    "\n",
    "ILSVRC에 제출된 모델들은 초기에는 높은 에러율 때문에 그다지 주목을 끌지 못했습니다. 하지만 2012년, **Alex Krizhevsky**가 주도하는 토론토 대학의 SuperVision이란 팀이 기존 모델들을 10% 가까이 따돌리는 당시로써는 엄청난 성능을 보여주는 모델을 제출하게 됩니다. 이것이 바로 현재 **AlexNet**이라는 이름으로 알려진 CNN 모델입니다. (여담으로 이 Alex Krizhevsky의 지도교수가 그 유명한 제프리 힌튼입니다.)\n",
    "\n",
    "<center><img src=\"./img/imagenet-breakthrough.png\" width=500></center>\n",
    "\n",
    "위 그래프는 매년 1위를 차지했던 모델들의 그래프인데, 2012년 AlexNet을 기점으로 에러율이 확 줄어드는 것을 확인할 수 있습니다. 이 AlexNet은 그 놀라운 성능 덕분에 많은 기계학습 관련 연구자들을 딥러닝에 뛰어들게 만들었습니다. 말 그대로 혁신(Breakthrough)이 일어난 것입니다.\n",
    "\n",
    "AlexNet이 기존 CNN들과 차별화된 가장 큰 특징은 바로 모델을 **GPU를 통해 훈련**하였다는 점입니다. 지금이야 딥러닝에 GPU를 쓰지 않는다는 생각을 할 수가 없을 정도지만 이런 생각을 처음 만들어준 것이 바로 AlexNet이라는 것입니다. 이는 그동안 CNN의 잠재능력이 컴퓨팅 하드웨어의 발전에 발목이 잡혀있었다는 것을 시사하기도 합니다. 그 외에도 **ReLU 활성화 함수**와 **Dropout**이라는 GPU 만큼이나 CNN 모델에서 빠지지 않는 것들이 AlexNet 논문에서 처음 소개되었습니다. 말 그대로 현대 CNN 모델의 아버지라 부르기에 손색이 없는 연구성과라 할 수 있겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5MXPT_iGyGU"
   },
   "source": [
    "이제 AlexNet의 구조를 알아보도록 하겠습니다. AlexNet 구조의 가장 큰 특징은 모델이 **두 갈래로 분리**되었다는 점입니다. 이는 하드웨어의 한계에 기인하는데, 당시 AlexNet을 훈련하기 위해 사용한 GPU(NVIDIA GeForce GTX 580, 3GB VRAM)의 메모리 용량이 AlexNet을 ImageNet으로 학습하기에 부족했기 때문에 두개의 GPU를 사용하였기 때문입니다. 그 점을 제외하고는 Max Pooling의 사용, 모델 끝단에서 Fully-connected layer의 사용 등 기본적인 구조 자체는 LeNet이 제시한 CNN의 구조를 충실히 따르고 있다고 볼 수 있습니다.\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdFkK2b%2FbtqBfs1qzAK%2FnCPCjOf5t9WyxEggoDTLUk%2Fimg.png\"\n",
    "alt=\"LeNet5\" align=\"center\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qusI-ezu1y63"
   },
   "source": [
    "이제 AlexNet이 처음 소개했다고 한 ReLU와 Dropout을 간략히 짚고 넘어가도록 하겠습니다. 먼저 ReLU는 활성화 함수의 이름으로, Rectified Linear Unit의 약자입니다.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2400/1*nrxtwp6rzqdFhgYh0x-eVw.png\" width=500>\n",
    "\n",
    "ReLU를 사용하기 이전에 CNN을 포함한 많은 인공 신경망 모델은 Sigmoid를 활성화 함수로 사용하였습니다. 하지만 위의 그림에서도 확인할 수 있듯이 Sigmoid는 $x$값이 커지거나 작아질수록 값이 거의 1이나 -1이 된다는 것을 확인할 수 있습니다. 이는 추후 설명할 **Vanishing Gradient** 문제를 야기하게 됩니다. 지금까지의 설명으로 쉽게 얘기하면 **활성화 함수 때문에 모델이 학습이 안되어버리는 현상**이 생기는 것입니다. 이 문제는 당연히 값이 계속 변하는 선형 함수 ($y=x$) 등을 사용하면 해결되지만, 단순히 선형 함수를 사용한다면 인공 신경망에서 layer를 여러개 쌓는 것에 아무 의미도 없어지게 됩니다. 즉, 모델의 **비선형성(non-linearity)** 이 사라져서 모델의 **표현력(representational power)** 이 굉장히 제한됩니다.\n",
    "\n",
    "따라서 비선형이면서도 $y=x$의 특징을 사용할 수 있는 함수를 고민하게 되었고 그 결과 등장한 것이 **ReLU** 활성화 함수입니다. 이 함수는 수식으로 나타내면 $y = max(0, x)$가 되는 매우 간단한 함수입니다. 즉, $x$가 양수이면 $y=x$를 따르고, 음수라면 모두 0으로 만드는 것입니다. 그에 따라 비선형이면서 $y=x$의 특징을 모두 사용할 수 있게 되는 것입니다. ReLU의 파급력을 생각하면 너무나 간단한 아이디어라고 할 수 있겠습니다.\n",
    "\n",
    "다음으로 소개한 **Dropout** 또한 그 파급력에 비하면 아이디어는 굉장히 간단합니다. 이는 아래 그림을 보면 이해가 훨씬 빨라집니다.\n",
    "\n",
    "<img src=\"./img/dropout.png\" width=500>\n",
    "\n",
    "Dropout은 인공 신경망에서 이전 layer와 다음 layer를 연결할 때, 일부 뉴런을 아예 비활성화 시켜서 연결을 끊어버리는 기법입니다. 비활성화 되는 뉴런은 임의로 선택됩니다. 그림에서 보면 Dropout이 적용된 경우 일부 뉴런이 비활성화 되어 연결이 끊어진 것을 확인할 수 있습니다. 이로 인한 효과는 모델 파라미터 수가 줄어들면서 모델이 데이터에 **과적합(Overfitting)** 되는 현상이 완화되는 것입니다. 이 기법은 모든 인공 신경망 모델에 적용할 수 있는 데다가 대부분의 경우에 유의미한 성능 향상을 보였기 때문에 사실상 딥러닝 모델의 필수요소로 자리잡게 됩니다. Dropout에 대해선 다음 이론에서 좀 더 자세히 다루도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 소개한 그림에 따라 AlexNet을 코드로 구현해보겠습니다. 다만 본 예제에서는 직접 훈련을 시킬 것이 아니기 때문에 두 갈래로 나눠진 모델을 하나로 합쳐서 구현하도록 하겠습니다. 실제로 훈련을 시킨다 하여도 현재 GPU는 당시에 비해 어마어마한 성능 향상을 이루고 GPU 메모리도 많이 늘어났기 때문에 AlexNet 정도의 모델은 굳이 GPU를 나눠서 훈련시킬 필요성은 거의 없어졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Btspqkkt5q9U"
   },
   "outputs": [],
   "source": [
    "def AlexNet(input_shape, num_classes):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    model = Sequential(name='AlexNet')\n",
    "    model.add(Conv2D(96, kernel_size=(11, 11), strides=4,\n",
    "                    padding='valid', activation='relu',\n",
    "                    input_shape=input_shape, kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None)) \n",
    "\n",
    "    model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= initializer))\n",
    "\n",
    "    model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= initializer))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= initializer))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                          padding= 'valid', data_format= None))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    # ImageNet의 클래스 개수는 1000개입니다.\n",
    "    model.add(Dense(1000, activation= 'relu'))\n",
    "    model.add(Dense(num_classes, activation= 'softmax'))\n",
    "\n",
    "    model.compile(optimizer= tfa.optimizers.SGDW(learning_rate=0.01,\\\n",
    "                momentum=0.9,weight_decay=0.0005),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkLZy9xhpMck"
   },
   "source": [
    "## 3. VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**논문**: [Very Deep Convolutional Networks for Large-Scale Image Recognition (ICLR 2015)](https://arxiv.org/abs/1409.1556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLzJ59xKwVB2"
   },
   "source": [
    "**VGGNet**은 옥스포드 대학의 연구팀 VGG(Visual Geometry Group)에 의해 개발된 모델로, 2014년 이미지넷 이미지 인식 대회에서 우승한 GoogLeNet에 이어 준우승을 한 모델입니다. 여기서 말하는 VGGNet은 16개 또는 19개의 층으로 구성된 모델을 의미합니다. (각각 VGG16, VGG19로 불립니다.)\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\"\n",
    "alt=\"LeNet5\" align=\"center\" border=\"0\"  width=\"600\" height=auto>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipp2nChhI1za"
   },
   "source": [
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\"\n",
    "alt=\"LeNet5\" align=\"center\" border=\"0\"  width=\"700\" height=auto>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVOzIoTs3FEt"
   },
   "source": [
    "VGGNet은 AlexNet과 한눈에 봐도 비슷한 구조를 가지고 있습니다. 다만 layer 수를 2배 정도로 늘려서 비약적인 성능 향상을 이루어 냈습니다. 본 강의에서는 다루지 않는 GoogLeNet(또는 Inception Network)은 아예 논문 제목이 **Going Deeper with Convolutions**일 정도로 layer를 깊게 쌓았다는 점을 강조합니다. 이렇듯 2010년대 중반에는 매년 계속되는 GPU 발전에 힘입어 layer를 계속 늘려갔고, 이는 곧 분류 성능 향상으로 이어졌습니다.\n",
    "\n",
    "VGGNet이 가지는 가장 큰 특징은 처음으로 모든 Convolutional layer의 커널(필터) 사이즈를 $3 \\times 3$으로 사용했다는 점입니다. 이전까지는 $5 \\times 5$ 도 사용하고 더 큰 사이즈도 사용하는 등 다채로운 사이즈를 사용했었으나, VGGNet을 기점으로 이후에 나온 대부분의 CNN은 핵심 Convolutional layer의 커널 크기를 $3 \\times 3$으로 쓰게 됩니다. VGGNet은 이렇듯 작은 사이즈의 커널을 사용함으로써 layer를 더 많이 사용함에도 파라미터 수의 증가를 상대적으로 최소화할 수 있었습니다. 그러나 모델이 깊어진 만큼 표현력이 좋아졌기 때문에 성능은 비약적으로 향상된 것입니다.\n",
    "\n",
    "아래 코드는 19개의 layer를 가지는 VGG19를 구현한 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f0ra0Xma54eg"
   },
   "outputs": [],
   "source": [
    "def VGG19(input_shape):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    model = Sequential(name='VGG')\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu', input_shape= input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding= 'same',\n",
    "                    activation= 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation= 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation= 'softmax'))\n",
    "\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(0.003),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**논문**: [Deep Residual Learning for Image Recognition (CVPR 2016)](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet**은 Microsoft 연구소(Microsoft Research)에서 개발한 모델로 2015년 ILSVRC 대회 우승 모델입니다. 위의 AlexNet에 등장한 그래프에서 사람의 에러율보다 더 낮은 에러율을 보이는 모델이기도 합니다. ResNet이 이와 같이 압도적인 성능을 보인 데에는 엄청나게 많은 layer를 사용한 점이 크게 기여하였습니다. 2014년 우승 모델인 GoogLeNet은 22개, 준우승한 VGGNet은 19개를 사용했는데, ResNet은 무려 최대 **152**개의 layer를 사용하였습니다. 순식간에 layer 수가 8배 가량 증가한 것입니다.\n",
    "\n",
    "<img src=\"./img/resnet.png\" width=300>\n",
    "\n",
    "하지만 ResNet 논문의 핵심 포인트는 이 layer 개수가 아닙니다. 이 핵심 포인트를 설명하기 위해서는 앞서 sigmoid와 ReLU 활성화 함수를 설명하면서 언급한 **Vanishing Gradient** 문제를 짚고 넘어가야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing Gradient 문제\n",
    "\n",
    "**Vanishing Gradient(기울기 소실) 문제**란 gradient descent와 back propogation 기반으로 학습하는 모델에서 나타나는 현상으로, backprop시 전달되는 gradient가 0에 가까워지는 현상을 의미합니다. 아시다시피 gradient descent를 사용하면 weight에서 계산된 gradient를 빼주면서 weight을 학습해 나가게 되는데, gradient가 0에 가깝다면 weight의 업데이트가 제대로 이루어지지 않을 것입니다. 즉, 이 상태가 되면 모델이 더 이상 학습되지 않을 것입니다. 이는 과적합(Overfitting)과는 다른 종류의 문제로, 과적합은 학습 데이터만 너무 잘 학습하는 게 문제라면 vanishing gradient는 오히려 학습 데이터에도 학습이 제대로 되지 않는 문제라 할 수 있습니다. 아래 그림에서는 각 layer가 받는 gradient의 크기를 검은색의 세기로 표현하였습니다.\n",
    "\n",
    "<img src=\"./img/vanishing-gradient.png\" width=500>\n",
    "\n",
    "이 현상이 나타나는 주요 원인으로는 앞서 ReLU 부분에서 설명한 sigmoid를 활성화 함수로 사용할 때가 있고, 두 번째로는 **모델을 너무 깊게 만들었을 때**, 즉 layer를 너무 많이 사용했을 때 나타나게 됩니다. Back propagation에서 gradient의 계산은 chain rule을 따라 하게 되는데, layer가 많아질수록 input쪽 layer에서는 chain rule에 관여한 곱셈의 개수가 많이 늘어날 것이고, 그러면 0에 가까운 값들이 여러번 곱해질 가능성도 높아지니 gradient가 사라질 위험이 높아집니다.\n",
    "\n",
    "(**참고**: 반대로 gradient가 너무 큰 값들을 계속 chain rule로 곱해가는 상황도 생각해볼 수 있을 것입니다. 이 경우에는 기울기 발산(Exploding Gradient) 문제라 부릅니다. 문제의 원인이 동일하기 때문에 사실상 기울기 소실과 같은 성질의 문제로 분류됩니다.)\n",
    "\n",
    "ResNet을 소개한 논문에서는 이 기울기 소실 문제를 **degradation problem**으로 정의하였고 이를 해결하기 위한 기법으로 아래에서 설명할 **residual connection**이란 것을 등장시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Connection\n",
    "\n",
    "위의 ResNet 그림을 유심히 보신 분들은 뭔가 화살표 사이에서 점프하는 듯이 연결되는 화살표가 추가된 점에 눈치채셨을 수도 있습니다. 이 부분이 바로 **Residual Connection**을 묘사한 부분입니다. **Residual Connection**이란 layer와 layer 사이를 건너뛰는 일종의 지름길에 해당하는 연결을 의미합니다. 일단 그림으로는 아래와 같습니다.\n",
    "\n",
    "<img src=\"./img/residual-connection.png\" width=500>\n",
    "\n",
    "그림에서 보면 알 수 있듯이 가운데 두개 layer를 건너뛰는 또 하나의 경로가 생긴 것을 확인할 수 있습니다. 이 경로로는 첫번째 layer에 들어갈 input인 $x$가 전달되어 두번째 layer의 output과 **더해집니다.** 이렇게 되면 back propagation으로 gradient를 전달할 때 layer의 output인 $F(x)$ 뿐만 아니라 $x$의 미분도 함께 계산되어 전달됩니다. 잘 아시다시피 단순히 $x$를 미분하면 $1$이기 때문에 gradient에 항상 **1이 더해져서 0에 가까워지는 문제를 원천봉쇄 할 수 있게 됩니다!** ResNet은 이 Residual Connection의 사용으로 AlexNet 이후로 CNN 모델에 또 한번의 혁신(breakthrough)을 이루어냈다 해도 과언이 아닙니다(단일 논문 인용수가 2021년 10월 기준 **9만번**이 넘습니다. 제프리 힌튼 같은 한 업계의 대가가 이뤄낸 총 인용수가 50만번임을 감안하면 **단일** 논문이 10만번에 가까운 게 어느 정도인지 감이 오실 겁니다). 이 덕분에 이후 등장하는 CNN들은 100개의 layer는 가볍게 사용하면서도 성능의 향상을 계속해서 이루어내게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 구현\n",
    "\n",
    "이제 이 ResNet을 구현하는 코드를 소개하도록 하겠습니다. ResNet은 residual connection 덕분에 layer 수의 변화가 굉장히 자유로운데, 아래 코드는 그 중 가장 가벼우면서 널리 사용되는 ResNet-18의 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D, BatchNormalization, Layer, Add\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ResnetBlock(Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.down_sample = down_sample\n",
    "        self.strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        self.conv_1 = Conv2D(self.channels, strides=self.strides[0], kernel_size=(3, 3),\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.channels, strides=self.strides[1], kernel_size=(3, 3),\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.down_sample:\n",
    "            # perform down sampling using stride of 2, according to [1].\n",
    "            self.res_conv = Conv2D(self.channels, strides=2, kernel_size=(1, 1),\n",
    "                                   padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "\n",
    "class ResNet18(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gPQt4z8xEYG"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSIJTal8xIBQ"
   },
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[이론4] CNN Architectures (LeNet-5, AlexNet, VGGNet) - 1차 검수 반영",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
