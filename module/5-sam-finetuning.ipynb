{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HuggingFace🤗 SAM Fine-tuning\n","\n","[HF SAM 공식문서](https://huggingface.co/docs/transformers/model_doc/sam)"]},{"cell_type":"markdown","metadata":{},"source":["## Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:03:02.061869Z","iopub.status.busy":"2024-09-28T11:03:02.060936Z","iopub.status.idle":"2024-09-28T11:03:02.068134Z","shell.execute_reply":"2024-09-28T11:03:02.067033Z","shell.execute_reply.started":"2024-09-28T11:03:02.061827Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from statistics import mean\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.nn.functional import threshold, normalize\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Transformers SAM modules"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:21.160044Z","iopub.status.busy":"2024-09-28T10:48:21.159605Z","iopub.status.idle":"2024-09-28T10:48:21.623926Z","shell.execute_reply":"2024-09-28T10:48:21.622961Z","shell.execute_reply.started":"2024-09-28T10:48:21.160008Z"},"trusted":true},"outputs":[],"source":["import transformers\n","hf_list = dir(transformers)\n","for module in hf_list:\n","    if \"Sam\" in module:\n","        print(module)"]},{"cell_type":"markdown","metadata":{},"source":["### 데이터셋 불러오기\n","유방암 초음파 진단 Segmentation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:04:17.203859Z","iopub.status.busy":"2024-09-28T11:04:17.203203Z","iopub.status.idle":"2024-09-28T11:04:18.615249Z","shell.execute_reply":"2024-09-28T11:04:18.614204Z","shell.execute_reply.started":"2024-09-28T11:04:17.203820Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"nielsr/breast-cancer\", split=\"train\")\n","\n","print(dataset['image'][:5])\n","print(dataset['label'][:5])"]},{"cell_type":"markdown","metadata":{},"source":["### 데이터 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:25.457662Z","iopub.status.busy":"2024-09-28T10:48:25.456731Z","iopub.status.idle":"2024-09-28T10:48:25.477241Z","shell.execute_reply":"2024-09-28T10:48:25.476355Z","shell.execute_reply.started":"2024-09-28T10:48:25.457616Z"},"trusted":true},"outputs":[],"source":["example = dataset[0]\n","example[\"image\"]"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:05.361869Z","iopub.status.busy":"2024-09-28T11:55:05.361466Z","iopub.status.idle":"2024-09-28T11:55:05.384172Z","shell.execute_reply":"2024-09-28T11:55:05.382971Z","shell.execute_reply.started":"2024-09-28T11:55:05.361830Z"},"trusted":true},"outputs":[],"source":["def show_mask(mask, ax, random_color=False):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    ax.imshow(mask_image)\n","\n","\n","def show_box(box, ax):\n","    x0, y0 = box[0], box[1]\n","    w, h = box[2] - box[0], box[3] - box[1]\n","    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))  \n","\n","def show_boxes_on_image(raw_image, boxes):\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(raw_image)\n","    for box in boxes:\n","        show_box(box, plt.gca())\n","    plt.axis('on')\n","    plt.show()\n","\n","def show_points_on_image(raw_image, input_points, input_labels=None):\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(raw_image)\n","    input_points = np.array(input_points)\n","    if input_labels is None:\n","        labels = np.ones_like(input_points[:, 0])\n","    else:\n","        labels = np.array(input_labels)\n","    show_points(input_points, labels, plt.gca())\n","    plt.axis('on')\n","    plt.show()\n","\n","def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(raw_image)\n","    input_points = np.array(input_points)\n","    if input_labels is None:\n","        labels = np.ones_like(input_points[:, 0])\n","    else:\n","        labels = np.array(input_labels)\n","    show_points(input_points, labels, plt.gca())\n","    for box in boxes:\n","        show_box(box, plt.gca())\n","    plt.axis('on')\n","    plt.show()\n","\n","\n","def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(raw_image)\n","    input_points = np.array(input_points)\n","    if input_labels is None:\n","        labels = np.ones_like(input_points[:, 0])\n","    else:\n","        labels = np.array(input_labels)\n","    show_points(input_points, labels, plt.gca())\n","    for box in boxes:\n","        show_box(box, plt.gca())\n","    plt.axis('on')\n","    plt.show()\n","\n","\n","def show_points(coords, labels, ax, marker_size=375):\n","    pos_points = coords[labels==1]\n","    neg_points = coords[labels==0]\n","    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","\n","\n","def show_masks_on_image(raw_image, masks, scores):\n","    masks = masks[0]\n","    if len(masks.shape) == 4:\n","        masks = masks.squeeze()\n","    if scores.shape[0] == 1:\n","        scores = scores.squeeze()\n","\n","    nb_predictions = scores.shape[-1]\n","    fig, axes = plt.subplots(1, nb_predictions, figsize=(15, 15))\n","\n","    for i, (mask, score) in enumerate(zip(masks, scores)):\n","        mask = mask.cpu().detach()\n","        axes[i].imshow(np.array(raw_image))\n","        show_mask(mask, axes[i])\n","        axes[i].title.set_text(f\"Mask {i+1}, Score: {score.item():.3f}\")\n","        axes[i].axis(\"off\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:44.816982Z","iopub.status.busy":"2024-09-28T10:48:44.816206Z","iopub.status.idle":"2024-09-28T10:48:49.780697Z","shell.execute_reply":"2024-09-28T10:48:49.779801Z","shell.execute_reply.started":"2024-09-28T10:48:44.816940Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","for i in range(5):\n","    axes[0][i].imshow(np.array(dataset[\"image\"][i]), cmap=\"gray\")\n","    axes[1][i].imshow(np.array(dataset[\"image\"][i]), cmap=\"gray\")\n","    ground_truth_seg = np.array(dataset[\"label\"][i])\n","    show_mask(ground_truth_seg, axes[1][i])\n","    axes[0][i].title.set_text(f\"Image {i}\")\n","    axes[0][i].axis(\"off\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 프롬프트 생성\n","- 프롬프트 1: bounding box\n","    - 마스크를 둘러 싼 Bbox\n","- 프롬프트 2: point\n","    - 마스크 내 임의의 점"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:49.791544Z","iopub.status.busy":"2024-09-28T10:48:49.791172Z","iopub.status.idle":"2024-09-28T10:48:49.800020Z","shell.execute_reply":"2024-09-28T10:48:49.799102Z","shell.execute_reply.started":"2024-09-28T10:48:49.791509Z"},"trusted":true},"outputs":[],"source":["def get_bounding_box(ground_truth_map):\n","    # Segmentation mask -> Bbox 좌표(xyxy) 변환\n","    y_indices, x_indices = np.where(ground_truth_map > 0)\n","    x_min, x_max = np.min(x_indices), np.max(x_indices)\n","    y_min, y_max = np.min(y_indices), np.max(y_indices)\n","    H, W = ground_truth_map.shape\n","    x_min = max(0, x_min - np.random.randint(0, 20))\n","    x_max = min(W, x_max + np.random.randint(0, 20))\n","    y_min = max(0, y_min - np.random.randint(0, 20))\n","    y_max = min(H, y_max + np.random.randint(0, 20))\n","    bbox = [x_min, y_min, x_max, y_max]\n","\n","    return bbox\n","\n","def get_point_prompt(ground_truth_map):\n","    # Segmentation mask에 속한 점을 추출 (ground_truth_map > 0인 좌표 중 하나)\n","    y_indices, x_indices = np.where(ground_truth_map > 0)\n","\n","    if len(x_indices) == 0 or len(y_indices) == 0:\n","        return None  # 만약 객체가 없으면 None 반환\n","\n","    # 점 하나를 랜덤으로 선택\n","    idx = np.random.randint(0, len(x_indices))\n","    point = (x_indices[idx], y_indices[idx])  # (x, y) 좌표로 반환\n","\n","    return point"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:49.957964Z","iopub.status.busy":"2024-09-28T10:48:49.957283Z","iopub.status.idle":"2024-09-28T10:48:50.088488Z","shell.execute_reply":"2024-09-28T10:48:50.087476Z","shell.execute_reply.started":"2024-09-28T10:48:49.957921Z"},"trusted":true},"outputs":[],"source":["_mask = get_bounding_box(np.array(dataset[\"label\"][0]))\n","_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:51.868338Z","iopub.status.busy":"2024-09-28T10:48:51.867933Z","iopub.status.idle":"2024-09-28T10:48:51.995630Z","shell.execute_reply":"2024-09-28T10:48:51.994699Z","shell.execute_reply.started":"2024-09-28T10:48:51.868298Z"},"trusted":true},"outputs":[],"source":["_point = get_point_prompt(np.array(dataset[\"label\"][0]))\n","_point"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset & DataLoader 클래스 선언"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:48:53.101208Z","iopub.status.busy":"2024-09-28T10:48:53.100241Z","iopub.status.idle":"2024-09-28T10:48:53.109889Z","shell.execute_reply":"2024-09-28T10:48:53.108671Z","shell.execute_reply.started":"2024-09-28T10:48:53.101166Z"},"trusted":true},"outputs":[],"source":["class SAMDataset(Dataset):\n","    def __init__(self, dataset, processor):\n","        self.dataset = dataset\n","        self.processor = processor\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        이미지와 프롬프트를 입력받아 마스크를 생성\n","        여기에선 lable(마스크)을 활용하여 두 가지 프롬프트(bbox, point)를 생성\n","        x: image, prompt1(bounding box), prompt2(point)\n","        y: segmentation mask\n","        \"\"\"\n","        item = self.dataset[idx]\n","        image = item[\"image\"].convert(\"RGB\")\n","        ground_truth_mask = np.array(item[\"label\"])\n","\n","        prompt_bbox = get_bounding_box(ground_truth_mask)\n","        prompt_point = get_point_prompt(ground_truth_mask)\n","\n","        # x: image, prompt\n","        inputs = self.processor(image, input_boxes=[[prompt_bbox]], input_points=[[prompt_point]], return_tensors=\"pt\")\n","\n","        # Processor을 통과하면 자동으로 batch 차원이 추가되므로 하나 제거\n","        inputs = {k:v.squeeze(0) for k, v in inputs.items()}\n","\n","        # y: segmentation mask\n","        inputs[\"ground_truth_mask\"] = ground_truth_mask\n","\n","        return inputs"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:49:03.097649Z","iopub.status.busy":"2024-09-28T10:49:03.096827Z","iopub.status.idle":"2024-09-28T10:49:07.578004Z","shell.execute_reply":"2024-09-28T10:49:07.576956Z","shell.execute_reply.started":"2024-09-28T10:49:03.097605Z"},"trusted":true},"outputs":[],"source":["from transformers import SamProcessor\n","\n","processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:04:34.538910Z","iopub.status.busy":"2024-09-28T11:04:34.538505Z","iopub.status.idle":"2024-09-28T11:04:34.605867Z","shell.execute_reply":"2024-09-28T11:04:34.604842Z","shell.execute_reply.started":"2024-09-28T11:04:34.538868Z"},"trusted":true},"outputs":[],"source":["sam_dataset = SAMDataset(dataset=dataset, processor=processor)\n","sam_dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:04:46.402658Z","iopub.status.busy":"2024-09-28T11:04:46.402255Z","iopub.status.idle":"2024-09-28T11:04:46.463490Z","shell.execute_reply":"2024-09-28T11:04:46.462381Z","shell.execute_reply.started":"2024-09-28T11:04:46.402620Z"},"trusted":true},"outputs":[],"source":["example = sam_dataset[0]\n","for k, v in example.items():\n","    print(k, v.shape)"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:45:15.951689Z","iopub.status.busy":"2024-09-28T11:45:15.951229Z","iopub.status.idle":"2024-09-28T11:45:15.957790Z","shell.execute_reply":"2024-09-28T11:45:15.956774Z","shell.execute_reply.started":"2024-09-28T11:45:15.951651Z"},"trusted":true},"outputs":[],"source":["train_size = int(len(sam_dataset) * 0.8)\n","test_size = len(sam_dataset) - train_size\n","train_dataset, test_dataset = random_split(sam_dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:04:49.993386Z","iopub.status.busy":"2024-09-28T11:04:49.992708Z","iopub.status.idle":"2024-09-28T11:04:50.235336Z","shell.execute_reply":"2024-09-28T11:04:50.234320Z","shell.execute_reply.started":"2024-09-28T11:04:49.993344Z"},"trusted":true},"outputs":[],"source":["batch = next(iter(train_loader))\n","for k, v in batch.items():\n","    print(k ,v.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## 학습"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 불러오기\n","\n","[공식 문서](https://github.com/huggingface/transformers/blob/v4.45.1/src/transformers/models/sam/modeling_sam.py#L1173)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:49:10.171658Z","iopub.status.busy":"2024-09-28T10:49:10.170696Z","iopub.status.idle":"2024-09-28T10:49:10.720554Z","shell.execute_reply":"2024-09-28T10:49:10.719521Z","shell.execute_reply.started":"2024-09-28T10:49:10.171599Z"},"trusted":true},"outputs":[],"source":["from transformers import SamModel \n","\n","model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n","\n","# 이미지 Encoder가 아닌 Mask prediction head(Decoder)만 학습\n","for name, param in model.named_parameters():\n","    if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n","        param.requires_grad_(False)"]},{"cell_type":"markdown","metadata":{},"source":["### Inputs\n","- input_points (`torch.FloatTensor` of shape `(batch_size, point_batch_size, num_points_per_image, 2)`):\n","    - Optional input points for the prompt encoder. The padding of the point is automatically done by the processor. `point_batch_size` refers to the number of masks that we want the model to predict per point. The model will output `point_batch_size` times 3 masks in total.\n","    \n","    \n","- input_labels (`torch.LongTensor` of shape `(batch_size, point_batch_size, num_points_per_image)`):\n","    - Optional input labels for the prompt encoder. The padding of the labels is automatically done by the processor, or can be fed by the user.\n","\n","\n","- input_boxes (`torch.FloatTensor` of shape `(batch_size, num_boxes_per_image, 4)`):\n","    - Optional input boxes for the prompt encoder. The padding of the boxes is automatically done by the processor. users can also pass manually the input boxes.\n","\n","\n","- input_masks (`torch.LongTensor` of shape `(batch_size, image_size, image_size)`):\n","    - Optional input masks for the prompt encoder."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:49:12.978431Z","iopub.status.busy":"2024-09-28T10:49:12.977696Z","iopub.status.idle":"2024-09-28T10:49:13.357734Z","shell.execute_reply":"2024-09-28T10:49:13.356680Z","shell.execute_reply.started":"2024-09-28T10:49:12.978387Z"},"trusted":true},"outputs":[],"source":["model.to(device)\n","dummy_image = torch.randn(4, 3, 1024, 1024).to(device)\n","dummy_boxes = torch.zeros(4, 1, 4).to(device)\n","dummy_points = torch.zeros(4, 1, 1, 2).to(device)\n","\n","batch = {\"pixel_values\": dummy_image, \"input_boxes\": dummy_boxes, \"input_points\": dummy_points}"]},{"cell_type":"markdown","metadata":{},"source":["### Outputs\n","- iou_scores (`torch.FloatTensor` of shape `(batch_size, num_masks)`):\n","    The iou scores of the predicted masks.\n","- pred_masks (`torch.FloatTensor` of shape `(batch_size, num_masks, height, width)`):\n","    The predicted low resolutions masks. Needs to be post-processed by the processor\n","- vision_hidden_states  (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n","    Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n","    one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n","\n","    Hidden-states of the vision model at the output of each layer plus the optional initial embedding outputs.\n","\n","- vision_attentions  (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n","    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n","    sequence_length)`.\n","\n","    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","    heads.\n","\n","- mask_decoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n","    Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n","    sequence_length)`.\n","\n","    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","    heads."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:51:43.001914Z","iopub.status.busy":"2024-09-28T10:51:43.001129Z","iopub.status.idle":"2024-09-28T10:52:34.617659Z","shell.execute_reply":"2024-09-28T10:52:34.616650Z","shell.execute_reply.started":"2024-09-28T10:51:43.001868Z"},"trusted":true},"outputs":[],"source":["cpu_device = torch.device(\"cpu\")\n","model = model.to(cpu_device)\n","output = model(pixel_values=batch[\"pixel_values\"].to(cpu_device), # 이미지\n","               input_boxes=batch[\"input_boxes\"].to(cpu_device),   # bbox prompt\n","#                input_points=batch[\"input_points\"].to(device), # point prompt\n","               multimask_outputs=True, # 논문 상 마스크를 3개씩 예측하나, False일 경우 하나만 예측\n","               return_dict=True)\n","\n","output.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:52:55.872911Z","iopub.status.busy":"2024-09-28T10:52:55.871981Z","iopub.status.idle":"2024-09-28T10:52:55.888955Z","shell.execute_reply":"2024-09-28T10:52:55.888032Z","shell.execute_reply.started":"2024-09-28T10:52:55.872865Z"},"trusted":true},"outputs":[],"source":["output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:52:59.840919Z","iopub.status.busy":"2024-09-28T10:52:59.840547Z","iopub.status.idle":"2024-09-28T10:52:59.847699Z","shell.execute_reply":"2024-09-28T10:52:59.846652Z","shell.execute_reply.started":"2024-09-28T10:52:59.840885Z"},"trusted":true},"outputs":[],"source":["print(output['iou_scores'])\n","print(f\"Best mask channel: {output['iou_scores'].argmax()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:53:02.548280Z","iopub.status.busy":"2024-09-28T10:53:02.547501Z","iopub.status.idle":"2024-09-28T10:53:02.554046Z","shell.execute_reply":"2024-09-28T10:53:02.553117Z","shell.execute_reply.started":"2024-09-28T10:53:02.548238Z"},"trusted":true},"outputs":[],"source":["output['pred_masks'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T10:53:05.604992Z","iopub.status.busy":"2024-09-28T10:53:05.604046Z","iopub.status.idle":"2024-09-28T10:53:05.610885Z","shell.execute_reply":"2024-09-28T10:53:05.609942Z","shell.execute_reply.started":"2024-09-28T10:53:05.604948Z"},"trusted":true},"outputs":[],"source":["output['iou_scores'].shape"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-trained model로 Zero-shot prediction 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:04:58.957336Z","iopub.status.busy":"2024-09-28T11:04:58.956447Z","iopub.status.idle":"2024-09-28T11:04:58.975017Z","shell.execute_reply":"2024-09-28T11:04:58.974122Z","shell.execute_reply.started":"2024-09-28T11:04:58.957295Z"},"trusted":true},"outputs":[],"source":["image = dataset[0][\"image\"]\n","image"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:07:29.020234Z","iopub.status.busy":"2024-09-28T11:07:29.019818Z","iopub.status.idle":"2024-09-28T11:07:29.082192Z","shell.execute_reply":"2024-09-28T11:07:29.081236Z","shell.execute_reply.started":"2024-09-28T11:07:29.020194Z"},"trusted":true},"outputs":[],"source":["gt_mask = np.array(dataset[0][\"label\"])\n","bbox_prompt = get_bounding_box(gt_mask)\n","point_prompt = get_point_prompt(gt_mask)\n","\n","inputs = inputs = processor(image, input_boxes=[[bbox_prompt]], input_points=[[point_prompt]], return_tensors=\"pt\").to(cpu_device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:35:53.934868Z","iopub.status.busy":"2024-09-28T11:35:53.934473Z","iopub.status.idle":"2024-09-28T11:35:54.242335Z","shell.execute_reply":"2024-09-28T11:35:54.241084Z","shell.execute_reply.started":"2024-09-28T11:35:53.934829Z"},"trusted":true},"outputs":[],"source":["print(bbox_prompt, point_prompt)\n","show_points_and_boxes_on_image(image, [bbox_prompt], [point_prompt])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:14:23.688363Z","iopub.status.busy":"2024-09-28T11:14:23.687463Z","iopub.status.idle":"2024-09-28T11:14:35.600889Z","shell.execute_reply":"2024-09-28T11:14:35.599892Z","shell.execute_reply.started":"2024-09-28T11:14:23.688323Z"},"trusted":true},"outputs":[],"source":["%%time\n","model.to(cpu_device)\n","model.eval()\n","\n","with torch.no_grad():\n","    outputs = model(**inputs, multimask_outputs=True)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:14:35.603360Z","iopub.status.busy":"2024-09-28T11:14:35.602857Z","iopub.status.idle":"2024-09-28T11:14:35.613927Z","shell.execute_reply":"2024-09-28T11:14:35.613080Z","shell.execute_reply.started":"2024-09-28T11:14:35.603313Z"},"trusted":true},"outputs":[],"source":["masks = processor.image_processor.post_process_masks(\n","    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n",")\n","scores = outputs.iou_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:37:00.162461Z","iopub.status.busy":"2024-09-28T11:37:00.161441Z","iopub.status.idle":"2024-09-28T11:37:00.453857Z","shell.execute_reply":"2024-09-28T11:37:00.452937Z","shell.execute_reply.started":"2024-09-28T11:37:00.162412Z"},"trusted":true},"outputs":[],"source":["ig, axes = plt.subplots()\n","\n","axes.imshow(np.array(image))\n","show_mask(gt_mask, axes)\n","axes.title.set_text(f\"Ground truth mask\")\n","axes.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:16:02.456207Z","iopub.status.busy":"2024-09-28T11:16:02.455769Z","iopub.status.idle":"2024-09-28T11:16:02.938517Z","shell.execute_reply":"2024-09-28T11:16:02.937565Z","shell.execute_reply.started":"2024-09-28T11:16:02.456169Z"},"trusted":true},"outputs":[],"source":["show_masks_on_image(image, masks, scores)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:19:05.763106Z","iopub.status.busy":"2024-09-28T11:19:05.762651Z","iopub.status.idle":"2024-09-28T11:19:05.769305Z","shell.execute_reply":"2024-09-28T11:19:05.768220Z","shell.execute_reply.started":"2024-09-28T11:19:05.763047Z"},"trusted":true},"outputs":[],"source":["def dice_loss(pred, target, smooth = 1.):\n","\n","    intersection = (pred * target).sum(dim=2).sum(dim=1)\n","    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=1) + target.sum(dim=2).sum(dim=1) + smooth)))\n","    \n","    return loss.mean()"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:19:14.669241Z","iopub.status.busy":"2024-09-28T11:19:14.668775Z","iopub.status.idle":"2024-09-28T11:19:14.675405Z","shell.execute_reply":"2024-09-28T11:19:14.674387Z","shell.execute_reply.started":"2024-09-28T11:19:14.669196Z"},"trusted":true},"outputs":[],"source":["from torch.optim import AdamW\n","\n","optimizer = AdamW(model.mask_decoder.parameters(), lr=1e-4, weight_decay=0)\n","\n","epochs = 20"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:13.478315Z","iopub.status.busy":"2024-09-28T11:55:13.477248Z","iopub.status.idle":"2024-09-28T11:55:13.492801Z","shell.execute_reply":"2024-09-28T11:55:13.491489Z","shell.execute_reply.started":"2024-09-28T11:55:13.478244Z"},"trusted":true},"outputs":[],"source":["def choose_best_mask(output):\n","    # IOU 점수 중 최대값을 가진 인덱스를 찾습니다. squeeze()로 차원 축소 후 argmax 실행\n","    best_channel_indices = output['iou_scores'].squeeze(1).argmax(dim=-1)\n","\n","    # 결과 마스크를 선택\n","    batch_size, _, num_masks, height, width = output['pred_masks'].shape\n","    best_masks = torch.zeros((batch_size, height, width)).float()\n","\n","    # 각 배치에 대해 최고의 마스크를 선택\n","    for i in range(batch_size):\n","        best_masks[i] = torch.sigmoid(output['pred_masks'][i, 0, best_channel_indices[i], :, :])\n","\n","    return best_masks"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:19:17.690328Z","iopub.status.busy":"2024-09-28T11:19:17.689499Z","iopub.status.idle":"2024-09-28T11:19:17.698186Z","shell.execute_reply":"2024-09-28T11:19:17.696988Z","shell.execute_reply.started":"2024-09-28T11:19:17.690285Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model, train_dataloader, optimizer, dice_loss, prompt_bbox=True):\n","    model.to(device)\n","    model.train()\n","    batch_loss = []\n","    for batch in tqdm(train_dataloader):\n","        if prompt_bbox:\n","            outputs = model(pixel_values=batch[\"pixel_values\"].to(device), input_boxes=batch[\"input_boxes\"].to(device), multimask_outputs=False)\n","        else: \n","            outputs = model(pixel_values=batch[\"pixel_values\"].to(device), input_points=batch[\"input_points\"].to(device), multimask_outputs=False)\n","        pred_mask = choose_best_mask(outputs).to(device)\n","        gt_mask = batch[\"ground_truth_mask\"].float().to(device)\n","        loss = dice_loss(pred_mask, gt_mask)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        batch_loss.append(loss.item())\n","    return sum(batch_loss) / len(batch_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:19:48.729877Z","iopub.status.busy":"2024-09-28T11:19:48.729483Z","iopub.status.idle":"2024-09-28T11:30:16.930905Z","shell.execute_reply":"2024-09-28T11:30:16.929951Z","shell.execute_reply.started":"2024-09-28T11:19:48.729837Z"},"trusted":true},"outputs":[],"source":["loss_history = []\n","for epoch in range(epochs):\n","    train_loss = train_one_epoch(model, train_loader, optimizer, dice_loss, prompt_bbox=False)\n","    print(f\"Epoch {epoch}, train loss: {train_loss}\")\n","    loss_history.append(train_loss)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:30:26.477125Z","iopub.status.busy":"2024-09-28T11:30:26.476691Z","iopub.status.idle":"2024-09-28T11:30:27.335117Z","shell.execute_reply":"2024-09-28T11:30:27.334085Z","shell.execute_reply.started":"2024-09-28T11:30:26.477076Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'SAM_model.pth')\n","torch.save(optimizer.state_dict(), 'optimizer.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:45:38.576292Z","iopub.status.busy":"2024-09-28T11:45:38.575466Z","iopub.status.idle":"2024-09-28T11:45:38.917753Z","shell.execute_reply":"2024-09-28T11:45:38.916812Z","shell.execute_reply.started":"2024-09-28T11:45:38.576252Z"},"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load('SAM_model.pth'))\n","optimizer.load_state_dict(torch.load('optimizer.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:46.702205Z","iopub.status.busy":"2024-09-28T11:55:46.701542Z","iopub.status.idle":"2024-09-28T11:55:46.721174Z","shell.execute_reply":"2024-09-28T11:55:46.720291Z","shell.execute_reply.started":"2024-09-28T11:55:46.702161Z"},"trusted":true},"outputs":[],"source":["idx = 55\n","image = dataset[idx][\"image\"]\n","image"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:51.949537Z","iopub.status.busy":"2024-09-28T11:55:51.948500Z","iopub.status.idle":"2024-09-28T11:55:52.015286Z","shell.execute_reply":"2024-09-28T11:55:52.012777Z","shell.execute_reply.started":"2024-09-28T11:55:51.949492Z"},"trusted":true},"outputs":[],"source":["gt_mask = np.array(dataset[idx][\"label\"])\n","bbox_prompt = get_bounding_box(gt_mask)\n","point_prompt = get_point_prompt(gt_mask)\n","\n","inputs = inputs = processor(image, input_boxes=[[bbox_prompt]], input_points=[[point_prompt]], return_tensors=\"pt\").to(cpu_device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:52.355251Z","iopub.status.busy":"2024-09-28T11:55:52.354839Z","iopub.status.idle":"2024-09-28T11:55:52.711814Z","shell.execute_reply":"2024-09-28T11:55:52.710191Z","shell.execute_reply.started":"2024-09-28T11:55:52.355210Z"},"trusted":true},"outputs":[],"source":["print(bbox_prompt, point_prompt)\n","show_points_and_boxes_on_image(image, [bbox_prompt], [point_prompt])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:55:52.777051Z","iopub.status.busy":"2024-09-28T11:55:52.776680Z","iopub.status.idle":"2024-09-28T11:56:05.342091Z","shell.execute_reply":"2024-09-28T11:56:05.341141Z","shell.execute_reply.started":"2024-09-28T11:55:52.777014Z"},"trusted":true},"outputs":[],"source":["%%time\n","model.to(cpu_device)\n","model.eval()\n","\n","with torch.no_grad():\n","    outputs = model(**inputs, multimask_outputs=True)"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:56:05.343982Z","iopub.status.busy":"2024-09-28T11:56:05.343656Z","iopub.status.idle":"2024-09-28T11:56:05.356148Z","shell.execute_reply":"2024-09-28T11:56:05.355311Z","shell.execute_reply.started":"2024-09-28T11:56:05.343947Z"},"trusted":true},"outputs":[],"source":["masks = processor.image_processor.post_process_masks(\n","    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n",")\n","scores = outputs.iou_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:56:05.357588Z","iopub.status.busy":"2024-09-28T11:56:05.357284Z","iopub.status.idle":"2024-09-28T11:56:05.667875Z","shell.execute_reply":"2024-09-28T11:56:05.666915Z","shell.execute_reply.started":"2024-09-28T11:56:05.357556Z"},"trusted":true},"outputs":[],"source":["ig, axes = plt.subplots()\n","\n","axes.imshow(np.array(image))\n","show_mask(gt_mask, axes)\n","axes.title.set_text(f\"Ground truth mask\")\n","axes.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T11:56:05.670617Z","iopub.status.busy":"2024-09-28T11:56:05.670191Z","iopub.status.idle":"2024-09-28T11:56:06.240066Z","shell.execute_reply":"2024-09-28T11:56:06.239123Z","shell.execute_reply.started":"2024-09-28T11:56:05.670570Z"},"trusted":true},"outputs":[],"source":["show_masks_on_image(image, masks, scores)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
